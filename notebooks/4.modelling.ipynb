{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "def train_model(model_name, model, X_train, y_train, X_test, y_test, results, training_threshold, dataset_name, X_val=None, y_val=None):\n",
    "    y_pred = [None]\n",
    "    training_time = [None]\n",
    "    training_completed = [False]\n",
    "\n",
    "    def train():\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            print(f\"Starting training for {model_name}...\")\n",
    "            \n",
    "            fit_kwargs = {}\n",
    "            if 'LightGBM' in model_name and X_val is not None and y_val is not None:\n",
    "                fit_kwargs = {\n",
    "                    'lightgbm__eval_set': [(X_val, y_val)],\n",
    "                    'lightgbm__early_stopping_rounds': 20\n",
    "                }\n",
    "            \n",
    "            model.fit(X_train, y_train, **fit_kwargs)\n",
    "            \n",
    "            y_pred[0] = model.predict(X_test)\n",
    "            training_time[0] = time.time() - start_time\n",
    "            training_completed[0] = True\n",
    "            print(f\"Completed training for {model_name} in {training_time[0]:.2f} seconds.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error training model {model_name}: {e}\")\n",
    "            training_completed[0] = False\n",
    "\n",
    "    thread = threading.Thread(target=train)\n",
    "    thread.start()\n",
    "    thread.join(timeout=training_threshold)\n",
    "\n",
    "    if not training_completed[0]:\n",
    "        print(f\"Model {model_name} exceeded training time ({training_threshold} seconds) or encountered an error.\")\n",
    "        y_pred[0] = np.nan\n",
    "        training_time[0] = np.nan\n",
    "    else:\n",
    "        mse = mean_squared_error(y_test, y_pred[0])\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_pred[0])\n",
    "        r_squared = r2_score(y_test, y_pred[0])\n",
    "\n",
    "        n = len(y_test)\n",
    "        p = X_test.shape[1]\n",
    "        if n > p + 1 and p > 0:\n",
    "            adjusted_r_squared = 1 - (1 - r_squared) * ((n - 1) / (n - p - 1))\n",
    "        else:\n",
    "            adjusted_r_squared = r_squared\n",
    "\n",
    "        print(f\"Model {model_name} trained successfully in {training_time[0]:.2f} seconds.\")\n",
    "        print(f\"MSE: {mse}, RMSE: {rmse}, MAE: {mae}, R²: {r_squared}, Adjusted R²: {adjusted_r_squared}\")\n",
    "\n",
    "        best_params = None\n",
    "        if isinstance(model, BayesSearchCV):\n",
    "            best_params = model.best_params_\n",
    "            print(f\"Best parameters for {model_name}: {best_params}\")\n",
    "\n",
    "        models_dir = os.path.join(\"models\", dataset_name)\n",
    "        os.makedirs(models_dir, exist_ok=True)\n",
    "        model_filename = f\"{model_name.replace(' ', '_')}.pkl\"\n",
    "        model_filepath = os.path.join(models_dir, model_filename)\n",
    "        with open(model_filepath, 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        print(f\"Model {model_name} saved to {model_filepath}\")\n",
    "\n",
    "        result = {\n",
    "            'Model': model_name,\n",
    "            'Dataset': dataset_name,\n",
    "            'Training Time (s)': training_time[0],\n",
    "            'MSE': mse,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'R2 Score': r_squared,\n",
    "            'Adjusted R2 Score': adjusted_r_squared\n",
    "        }\n",
    "        if best_params:\n",
    "            result['Best Params'] = str(best_params)\n",
    "        results.append(result)\n",
    "\n",
    "def main():\n",
    "    param_spaces = {\n",
    "        'Ridge Regression': {\n",
    "            'ridge__alpha': Real(0.1, 10.0, prior='log-uniform')\n",
    "        },\n",
    "        'Lasso Regression': {\n",
    "            'lasso__alpha': Real(0.01, 1.0, prior='log-uniform')\n",
    "        },\n",
    "        'Elastic Net Regression': {\n",
    "            'elasticnet__alpha': Real(0.01, 1.0, prior='log-uniform'),\n",
    "            'elasticnet__l1_ratio': Real(0.1, 0.9)\n",
    "        },\n",
    "        'LightGBM Regression': {\n",
    "            'lightgbm__num_leaves': Integer(31, 50),\n",
    "            'lightgbm__learning_rate': Real(0.01, 0.05, prior='log-uniform'),\n",
    "            'lightgbm__n_estimators': Integer(100, 200)\n",
    "        },\n",
    "        'Random Forest Regression': {\n",
    "            'randomforest__n_estimators': Integer(50, 100),\n",
    "            'randomforest__max_depth': Categorical([5, 10]),\n",
    "            'randomforest__min_samples_split': Integer(2, 5)\n",
    "        },\n",
    "        'XGBoost Regression': {\n",
    "            'xgboost__learning_rate': Real(0.01, 0.05, prior='log-uniform'),\n",
    "            'xgboost__max_depth': Integer(3, 5),\n",
    "            'xgboost__n_estimators': Integer(100, 200)\n",
    "        }\n",
    "    }\n",
    "    pipelines = {\n",
    "        'Linear Regression': Pipeline([\n",
    "            ('linearregression', LinearRegression())\n",
    "        ]),\n",
    "        'Ridge Regression': Pipeline([\n",
    "            ('ridge', Ridge())\n",
    "        ]),\n",
    "        'Lasso Regression': Pipeline([\n",
    "            ('lasso', Lasso())\n",
    "        ]),\n",
    "        'Elastic Net Regression': Pipeline([\n",
    "            ('elasticnet', ElasticNet())\n",
    "        ]),\n",
    "        'LightGBM Regression': Pipeline([\n",
    "            ('lightgbm', LGBMRegressor())\n",
    "        ]),\n",
    "        'Random Forest Regression': Pipeline([\n",
    "            ('randomforest', RandomForestRegressor())\n",
    "        ]),\n",
    "        'XGBoost Regression': Pipeline([\n",
    "            ('xgboost', xgb.XGBRegressor(use_label_encoder=False, eval_metric='rmse'))\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "    models = {}\n",
    "    for name, pipeline in pipelines.items():\n",
    "        if name in param_spaces:\n",
    "            models[name] = BayesSearchCV(\n",
    "                estimator=pipeline,\n",
    "                search_spaces=param_spaces[name],\n",
    "                cv=3,\n",
    "                scoring='r2',\n",
    "                n_jobs=1,\n",
    "                verbose=1,\n",
    "                n_iter=10,\n",
    "                random_state=42\n",
    "            )\n",
    "        else:\n",
    "            models[name] = pipeline\n",
    "\n",
    "    # Training threshold\n",
    "    training_threshold = 7200  # seconds\n",
    "\n",
    "    # List of datasets\n",
    "    datasets = ['dataset1', 'dataset5']\n",
    "\n",
    "    # Results folder\n",
    "    results_dir = \"model_results\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "    # Models directory\n",
    "    models_dir = \"models\"\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "    # Process each dataset\n",
    "    for dataset_name in datasets:\n",
    "        print(f\"\\nProcessing {dataset_name}\")\n",
    "\n",
    "        # Load pre-split data\n",
    "        data_path = f\"/home/dev/project/modelling/preprocessing/results/{dataset_name}\"\n",
    "        try:\n",
    "            train_data = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n",
    "            test_data = pd.read_csv(os.path.join(data_path, \"test.csv\"))\n",
    "            val_data = pd.read_csv(os.path.join(data_path, \"val.csv\"))\n",
    "            print(f\"Successfully loaded pre-split data for {dataset_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data for {dataset_name}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # drop column 'mssv' if it exists\n",
    "        if 'mssv' in train_data.columns:\n",
    "            train_data = train_data.drop(columns=['mssv'])\n",
    "            test_data = test_data.drop(columns=['mssv'])\n",
    "            val_data = val_data.drop(columns=['mssv'])\n",
    "        \n",
    "        # Define target variable\n",
    "        target_variable = 'diem_hp'\n",
    "        if target_variable not in train_data.columns:\n",
    "            print(f\"Target variable '{target_variable}' not found in training data for dataset '{dataset_name}'. Skipping this dataset.\")\n",
    "            continue\n",
    "\n",
    "        # Separate features and target\n",
    "        X_train = train_data.drop(columns=[target_variable])\n",
    "        y_train = train_data[target_variable]\n",
    "        X_test = test_data.drop(columns=[target_variable])\n",
    "        y_test = test_data[target_variable]\n",
    "        X_val = val_data.drop(columns=[target_variable])\n",
    "        y_val = val_data[target_variable]\n",
    "\n",
    "        # Handle missing values\n",
    "        X_train = X_train.fillna(0)\n",
    "        X_test = X_test.fillna(0)\n",
    "        X_val = X_val.fillna(0)\n",
    "        y_train = y_train.fillna(0)\n",
    "        y_test = y_test.fillna(0)\n",
    "        y_val = y_val.fillna(0)\n",
    "\n",
    "        print(\"All features are now numeric and missing values are handled.\")\n",
    "\n",
    "        # Prepare results storage\n",
    "        results = []\n",
    "\n",
    "        # Train and evaluate each model\n",
    "        for model_name, model in models.items():\n",
    "            print(f\"\\nTraining model: {model_name}\")\n",
    "            train_model(\n",
    "                model_name=model_name,\n",
    "                model=model,\n",
    "                X_train=X_train,\n",
    "                y_train=y_train,\n",
    "                X_test=X_test,\n",
    "                y_test=y_test,\n",
    "                results=results,\n",
    "                training_threshold=training_threshold,\n",
    "                dataset_name=dataset_name\n",
    "            )\n",
    "\n",
    "        # Save results to CSV\n",
    "        results_df = pd.DataFrame(results)\n",
    "        dataset_results_dir = os.path.join(results_dir, dataset_name)\n",
    "        os.makedirs(dataset_results_dir, exist_ok=True)\n",
    "        results_file = os.path.join(dataset_results_dir, 'model_results.csv')\n",
    "        results_df.to_csv(results_file, index=False)\n",
    "        print(f\"Results for {dataset_name} saved to {results_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
