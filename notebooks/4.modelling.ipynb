{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import threading\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "\n",
    "def train_model(\n",
    "    model_name,\n",
    "    model,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    results,\n",
    "    training_threshold,\n",
    "    dataset_name,\n",
    "    is_optimized=False,\n",
    "    X_val=None,\n",
    "    y_val=None\n",
    "):\n",
    "    y_pred = [None]\n",
    "    training_time = [None]\n",
    "    optimization_time = [0]\n",
    "    training_completed = [False]\n",
    "\n",
    "    def train():\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            model_type = \"Optimized\" if is_optimized else \"Default\"\n",
    "\n",
    "            if isinstance(model, BayesSearchCV) and is_optimized:\n",
    "                # Perform parameter optimization\n",
    "                opt_start = time.time()\n",
    "                model.fit(X_train, y_train)\n",
    "                optimization_time[0] = time.time() - opt_start\n",
    "            else:\n",
    "                # Default or duplicated \"optimized\" training (for models without optimization)\n",
    "                if 'lightgbm' in model.get_params():\n",
    "                    # Removed early stopping logic here\n",
    "                    lgb_estimator = model.named_steps['lightgbm']\n",
    "                    lgb_estimator.fit(X_train, y_train)\n",
    "                else:\n",
    "                    model.fit(X_train, y_train)\n",
    "\n",
    "            y_pred[0] = model.predict(X_test)\n",
    "            training_time[0] = time.time() - start_time\n",
    "            training_completed[0] = True\n",
    "        except Exception as e:\n",
    "            print(f\"Error training {model_name} ({model_type}): {e}\")\n",
    "            training_completed[0] = False\n",
    "\n",
    "    thread = threading.Thread(target=train)\n",
    "    thread.start()\n",
    "    thread.join(timeout=training_threshold)\n",
    "\n",
    "    if not training_completed[0]:\n",
    "        print(f\"Model {model_name} ({'Optimized' if is_optimized else 'Default'}) exceeded training time ({training_threshold}s) or failed.\")\n",
    "        y_pred[0] = np.nan\n",
    "        training_time[0] = np.nan\n",
    "    else:\n",
    "        # Evaluate performance\n",
    "        mse = mean_squared_error(y_test, y_pred[0])\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, y_pred[0])\n",
    "        r_squared = r2_score(y_test, y_pred[0])\n",
    "\n",
    "        n = len(y_test)\n",
    "        p = X_test.shape[1]\n",
    "        adjusted_r_squared = 1 - (1 - r_squared) * ((n - 1) / (n - p - 1)) if n > p + 1 and p > 0 else r_squared\n",
    "\n",
    "        result = {\n",
    "            'Model': f\"{model_name} ({'Optimized' if is_optimized else 'Default'})\",\n",
    "            'Dataset': dataset_name,\n",
    "            'Parameter Type': 'Optimized' if is_optimized else 'Default',\n",
    "            'Training Time (s)': training_time[0],\n",
    "            'Optimization Time (s)': optimization_time[0],\n",
    "            'MSE': mse,\n",
    "            'RMSE': rmse,\n",
    "            'MAE': mae,\n",
    "            'R2 Score': r_squared,\n",
    "            'Adjusted R2 Score': adjusted_r_squared\n",
    "        }\n",
    "\n",
    "        if isinstance(model, BayesSearchCV) and is_optimized:\n",
    "            result['Best Params'] = str(model.best_params_)\n",
    "        elif not is_optimized:\n",
    "            result['Parameters'] = str(model.get_params())\n",
    "\n",
    "        results.append(result)\n",
    "\n",
    "def main():\n",
    "    # Default parameters\n",
    "    default_params = {\n",
    "        'Linear Regression': {},\n",
    "        'Ridge Regression': {'ridge__alpha': 1.0},\n",
    "        'Lasso Regression': {'lasso__alpha': 0.1},\n",
    "        'Elastic Net Regression': {\n",
    "            'elasticnet__alpha': 0.1,\n",
    "            'elasticnet__l1_ratio': 0.5\n",
    "        },\n",
    "        'Random Forest Regression': {\n",
    "            'randomforest__n_estimators': 100,\n",
    "            'randomforest__max_depth': 10,\n",
    "            'randomforest__min_samples_split': 2\n",
    "        },\n",
    "        'XGBoost Regression': {\n",
    "            'xgboost__learning_rate': 0.01,\n",
    "            'xgboost__max_depth': 3,\n",
    "            'xgboost__n_estimators': 100\n",
    "        },\n",
    "        'LightGBM Regression': {}\n",
    "    }\n",
    "\n",
    "    # Parameter spaces for optimization\n",
    "    param_spaces = {\n",
    "        'Ridge Regression': {\n",
    "            'ridge__alpha': Real(0.1, 5.0, prior='log-uniform')\n",
    "        },\n",
    "        'Lasso Regression': {\n",
    "            'lasso__alpha': Real(0.01, 0.5, prior='log-uniform')\n",
    "        },\n",
    "        'Elastic Net Regression': {\n",
    "            'elasticnet__alpha': Real(0.01, 0.5, prior='log-uniform'),\n",
    "            'elasticnet__l1_ratio': Real(0.2, 0.8)\n",
    "        },\n",
    "        'LightGBM Regression': {\n",
    "            'lightgbm__num_leaves': Integer(20, 40),\n",
    "            'lightgbm__learning_rate': Real(0.01, 0.03, prior='log-uniform'),\n",
    "            'lightgbm__n_estimators': Integer(50, 150)\n",
    "        },\n",
    "        'Random Forest Regression': {\n",
    "            'randomforest__n_estimators': Integer(50, 100),\n",
    "            'randomforest__max_depth': Categorical([5, 10]),\n",
    "            'randomforest__min_samples_split': Integer(2, 4)\n",
    "        },\n",
    "        'XGBoost Regression': {\n",
    "            'xgboost__learning_rate': Real(0.01, 0.03, prior='log-uniform'),\n",
    "            'xgboost__max_depth': Integer(3, 5),\n",
    "            'xgboost__n_estimators': Integer(50, 150)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Pipelines\n",
    "    pipelines = {\n",
    "        'Linear Regression': Pipeline([('linearregression', LinearRegression())]),\n",
    "        'Ridge Regression': Pipeline([('ridge', Ridge())]),\n",
    "        'Lasso Regression': Pipeline([('lasso', Lasso())]),\n",
    "        'Elastic Net Regression': Pipeline([('elasticnet', ElasticNet())]),\n",
    "        'LightGBM Regression': Pipeline([\n",
    "            ('lightgbm', LGBMRegressor(num_leaves=31, learning_rate=0.01, n_estimators=100))\n",
    "        ]),\n",
    "        'Random Forest Regression': Pipeline([('randomforest', RandomForestRegressor())]),\n",
    "        'XGBoost Regression': Pipeline([\n",
    "            ('xgboost', xgb.XGBRegressor(use_label_encoder=False, eval_metric='rmse'))\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    # Set default params\n",
    "    for name, pipeline in pipelines.items():\n",
    "        if name in default_params and default_params[name]:\n",
    "            pipeline.set_params(**default_params[name])\n",
    "\n",
    "    # Create optimized models\n",
    "    models_optimized = {}\n",
    "    for name, pipeline in pipelines.items():\n",
    "        if name in param_spaces:\n",
    "            models_optimized[name] = BayesSearchCV(\n",
    "                estimator=pipeline,\n",
    "                search_spaces=param_spaces[name],\n",
    "                cv=3,\n",
    "                scoring='r2',\n",
    "                n_jobs=1,\n",
    "                verbose=1,\n",
    "                n_iter=5,\n",
    "                random_state=42\n",
    "            )\n",
    "        else:\n",
    "            # If no optimization, reuse pipeline as \"optimized\"\n",
    "            models_optimized[name] = pipeline\n",
    "\n",
    "    training_threshold = 7200\n",
    "    datasets = ['dataset1', 'dataset5']\n",
    "\n",
    "    results_dir = \"model_results\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    models_dir = \"models\"\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "    for dataset_name in datasets:\n",
    "        print(f\"\\nProcessing {dataset_name}\")\n",
    "        data_path = f\"/home/dev/project/modelling/preprocessing/results/{dataset_name}\"\n",
    "\n",
    "        try:\n",
    "            train_data = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n",
    "            test_data = pd.read_csv(os.path.join(data_path, \"test.csv\"))\n",
    "            val_data = pd.read_csv(os.path.join(data_path, \"val.csv\"))\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data for {dataset_name}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Remove 'mssv' if present\n",
    "        for df in [train_data, test_data, val_data]:\n",
    "            if 'mssv' in df.columns:\n",
    "                df.drop(columns=['mssv'], inplace=True)\n",
    "\n",
    "        target_variable = 'diem_hp'\n",
    "        if target_variable not in train_data.columns:\n",
    "            print(f\"Target variable '{target_variable}' not found in {dataset_name}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        X_train = train_data.drop(columns=[target_variable]).fillna(0)\n",
    "        y_train = train_data[target_variable].fillna(0)\n",
    "        X_test = test_data.drop(columns=[target_variable]).fillna(0)\n",
    "        y_test = test_data[target_variable].fillna(0)\n",
    "        X_val = val_data.drop(columns=[target_variable]).fillna(0)\n",
    "        y_val = val_data[target_variable].fillna(0)\n",
    "\n",
    "        results = []\n",
    "\n",
    "        # First run: Default parameters\n",
    "        for model_name, pipeline in pipelines.items():\n",
    "            print(f\"\\nTraining {model_name} (Default)...\")\n",
    "            train_model(\n",
    "                model_name=model_name,\n",
    "                model=pipeline,\n",
    "                X_train=X_train,\n",
    "                y_train=y_train,\n",
    "                X_test=X_test,\n",
    "                y_test=y_test,\n",
    "                results=results,\n",
    "                training_threshold=training_threshold,\n",
    "                dataset_name=dataset_name,\n",
    "                is_optimized=False,\n",
    "                X_val=X_val,\n",
    "                y_val=y_val\n",
    "            )\n",
    "\n",
    "        # Second run: Optimized parameters\n",
    "        for model_name, model in models_optimized.items():\n",
    "            if model_name in param_spaces:\n",
    "                print(f\"\\nTraining {model_name} (Optimized)...\")\n",
    "                train_model(\n",
    "                    model_name=model_name,\n",
    "                    model=model,\n",
    "                    X_train=X_train,\n",
    "                    y_train=y_train,\n",
    "                    X_test=X_test,\n",
    "                    y_test=y_test,\n",
    "                    results=results,\n",
    "                    training_threshold=training_threshold,\n",
    "                    dataset_name=dataset_name,\n",
    "                    is_optimized=True,\n",
    "                    X_val=X_val,\n",
    "                    y_val=y_val\n",
    "                )\n",
    "            else:\n",
    "                # No optimization available; duplicate default run as \"Optimized\"\n",
    "                print(f\"\\n{model_name} has no optimization; duplicating Default as Optimized...\")\n",
    "                train_model(\n",
    "                    model_name=model_name,\n",
    "                    model=pipelines[model_name],\n",
    "                    X_train=X_train,\n",
    "                    y_train=y_train,\n",
    "                    X_test=X_test,\n",
    "                    y_test=y_test,\n",
    "                    results=results,\n",
    "                    training_threshold=training_threshold,\n",
    "                    dataset_name=dataset_name,\n",
    "                    is_optimized=True,\n",
    "                    X_val=X_val,\n",
    "                    y_val=y_val\n",
    "                )\n",
    "\n",
    "        # Save results\n",
    "        results_df = pd.DataFrame(results)\n",
    "        dataset_results_dir = os.path.join(results_dir, dataset_name)\n",
    "        os.makedirs(dataset_results_dir, exist_ok=True)\n",
    "        results_file = os.path.join(dataset_results_dir, 'model_results_comparison.csv')\n",
    "        results_df.to_csv(results_file, index=False)\n",
    "        print(f\"Results for {dataset_name} saved to {results_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
