{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1xvkGyo5DpdaN_lr1vViby75JIWnH5L3V","authorship_tag":"ABX9TyMjqG3tKkMivgjc28anHukC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"bO3GGiUuZcP4","executionInfo":{"status":"ok","timestamp":1733666026414,"user_tz":-420,"elapsed":12525,"user":{"displayName":"Poser T","userId":"07695625075066244495"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ef3eda7b-f17c-44be-e230-f28005a1fa54"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n","Dask dataframe query planning is disabled because dask-expr is not installed.\n","\n","You can install it with `pip install dask[dataframe]` or `conda install dask`.\n","This will raise in a future version.\n","\n","  warnings.warn(msg, FutureWarning)\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import re\n","import threading\n","import time\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n","from lightgbm import LGBMRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.svm import SVR\n","import xgboost as xgb"]},{"cell_type":"code","source":["df_org = pd.read_csv('/content/drive/MyDrive/Nhom8_DS317.P11/Đồ án môn học/Huấn luyện mô hình/Kết quả ML/dataset/dataset5.csv')"],"metadata":{"id":"d-ovDfqqfWXW","executionInfo":{"status":"ok","timestamp":1733666029687,"user_tz":-420,"elapsed":3278,"user":{"displayName":"Poser T","userId":"07695625075066244495"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["df_org.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ct7ujllafuF4","executionInfo":{"status":"ok","timestamp":1733666029688,"user_tz":-420,"elapsed":14,"user":{"displayName":"Poser T","userId":"07695625075066244495"}},"outputId":"93b3c39a-02b0-4202-ec1c-f68fc43fea75"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['Unnamed: 0', 'mssv', 'mamh', 'malop', 'sotc', 'hocky', 'namhoc',\n","       'diem_qt', 'diem_th', 'diem_gk', 'diem_ck', 'diem_hp', 'trangthai',\n","       'tinhtrang', 'mamh_tt', 'namsinh', 'gioitinh', 'noisinh', 'lopsh',\n","       'khoa', 'hedt', 'khoahoc', 'dtbhk1', 'dtbhk2', 'dtbhk3', 'dtbhk4',\n","       'dtbhk5', 'dtbhk6', 'dtbhk7', 'dtbhk8', 'dtbhk9', 'dtbhk10', 'dtbhk11',\n","       'dtbhk12', 'dtbhk13', 'dtbhk14', 'dtbhk15', 'dtbhk16', 'dtbhk17',\n","       'dtbhk18', 'dtbhk19', 'dtbhk20', 'dtbhk21', 'dtbhk22', 'sotchk1',\n","       'sotchk2', 'sotchk3', 'sotchk4', 'sotchk5', 'sotchk6', 'sotchk7',\n","       'sotchk8', 'sotchk9', 'sotchk10', 'sotchk11', 'sotchk12', 'sotchk13',\n","       'sotchk14', 'sotchk15', 'sotchk16', 'sotchk17', 'sotchk18', 'sotchk19',\n","       'sotchk20', 'sotchk21', 'sotchk22', 'namhoc_monhoc', 'hocky_monhoc',\n","       'gap_hocky', 'hocky_monhoc_count', 'namhoc_monhoc_count'],\n","      dtype='object')"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["df_org.drop(columns=['Unnamed: 0', 'mssv','diem_qt', 'diem_th', 'diem_gk', 'diem_ck'], axis = 1, inplace = True)"],"metadata":{"id":"DWVSZwbJfjkJ","executionInfo":{"status":"ok","timestamp":1733666029688,"user_tz":-420,"elapsed":12,"user":{"displayName":"Poser T","userId":"07695625075066244495"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["df_added = df_org.copy()\n","df = df_org.drop(columns=['namhoc_monhoc', 'hocky_monhoc', 'gap_hocky', 'hocky_monhoc_count', 'namhoc_monhoc_count'], axis = 1)"],"metadata":{"id":"s7xkY0GLgW_o","executionInfo":{"status":"ok","timestamp":1733666029688,"user_tz":-420,"elapsed":12,"user":{"displayName":"Poser T","userId":"07695625075066244495"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["df.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TnJRQqk-lMuk","executionInfo":{"status":"ok","timestamp":1733666029688,"user_tz":-420,"elapsed":11,"user":{"displayName":"Poser T","userId":"07695625075066244495"}},"outputId":"1c8d54c5-7336-4c0f-8c32-93ff038d5019"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['mamh', 'malop', 'sotc', 'hocky', 'namhoc', 'diem_hp', 'trangthai',\n","       'tinhtrang', 'mamh_tt', 'namsinh', 'gioitinh', 'noisinh', 'lopsh',\n","       'khoa', 'hedt', 'khoahoc', 'dtbhk1', 'dtbhk2', 'dtbhk3', 'dtbhk4',\n","       'dtbhk5', 'dtbhk6', 'dtbhk7', 'dtbhk8', 'dtbhk9', 'dtbhk10', 'dtbhk11',\n","       'dtbhk12', 'dtbhk13', 'dtbhk14', 'dtbhk15', 'dtbhk16', 'dtbhk17',\n","       'dtbhk18', 'dtbhk19', 'dtbhk20', 'dtbhk21', 'dtbhk22', 'sotchk1',\n","       'sotchk2', 'sotchk3', 'sotchk4', 'sotchk5', 'sotchk6', 'sotchk7',\n","       'sotchk8', 'sotchk9', 'sotchk10', 'sotchk11', 'sotchk12', 'sotchk13',\n","       'sotchk14', 'sotchk15', 'sotchk16', 'sotchk17', 'sotchk18', 'sotchk19',\n","       'sotchk20', 'sotchk21', 'sotchk22'],\n","      dtype='object')"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["def split_data_by_group(data, group_col, train_ratio=0.8, val_ratio=0.2, test_ratio=None):\n","    \"\"\"\n","    Splits the data based on 'namhoc' column and then by group.\n","    - Data with namhoc <= 2020: split into train (80%) and validation (20%)\n","    - Data with namhoc > 2020: assigned to test set\n","\n","    Parameters:\n","    - data (pd.DataFrame): The dataset to split\n","    - group_col (str): The column name to group by\n","    - train_ratio (float): Proportion of historical data for training (default 0.8)\n","    - val_ratio (float): Proportion of historical data for validation (default 0.2)\n","    - test_ratio: Not used, kept for compatibility\n","\n","    Returns:\n","    - train_set (pd.DataFrame): Training set\n","    - val_set (pd.DataFrame): Validation set\n","    - test_set (pd.DataFrame): Testing set\n","    \"\"\"\n","    assert 'namhoc' in data.columns, \"'namhoc' column must exist in the dataset\"\n","    assert abs(train_ratio + val_ratio - 1.0) < 1e-5, \"Train and validation ratios must sum to 1\"\n","\n","    # Validate namhoc values\n","    print(f\"\\nnamhoc value counts:\\n{data['namhoc'].value_counts().sort_index()}\")\n","    if data['namhoc'].isna().any():\n","        print(\"Warning: Found NaN values in namhoc column. Filling with 0...\")\n","        data['namhoc'] = data['namhoc'].fillna(0)\n","\n","    # First split: separate historical and future data\n","    historical_data = data[data['namhoc'] <= 2020].copy()\n","    test_set = data[data['namhoc'] > 2020].copy()\n","\n","    print(f\"\\nInitial split sizes:\")\n","    print(f\"Historical data (<=2020): {len(historical_data)} samples\")\n","    print(f\"Future data (>2020): {len(test_set)} samples\")\n","\n","    if len(historical_data) == 0:\n","        print(\"Warning: No historical data found. Using 70-30 split on all data.\")\n","        historical_data = data.copy()\n","        test_set = pd.DataFrame()\n","\n","    train_set = pd.DataFrame()\n","    val_set = pd.DataFrame()\n","\n","    # Process historical data by groups\n","    grouped = historical_data.groupby(group_col)\n","    print(f\"\\nNumber of groups: {len(grouped)}\")\n","\n","    for group, group_data in grouped:\n","        n_samples = len(group_data)\n","        if n_samples < 2:\n","            train_set = pd.concat([train_set, group_data], ignore_index=True)\n","            print(f\"Group '{group}' has only {n_samples} sample(s). Assigned to training set.\")\n","            continue\n","\n","        try:\n","            # Split into train and validation\n","            train, val = train_test_split(\n","                group_data,\n","                test_size=val_ratio,\n","                random_state=42,\n","                shuffle=True\n","            )\n","\n","            train_set = pd.concat([train_set, train], ignore_index=True)\n","            val_set = pd.concat([val_set, val], ignore_index=True)\n","            print(f\"Group '{group}' split into {len(train)} train and {len(val)} validation samples.\")\n","        except ValueError as e:\n","            print(f\"Error splitting group '{group}': {e}. Assigning all to training set.\")\n","            train_set = pd.concat([train_set, group_data], ignore_index=True)\n","\n","    # Validate final sets\n","    if len(train_set) == 0:\n","        print(\"Warning: Empty training set. Using 80% of all data for training.\")\n","        train_set = data.sample(frac=0.8, random_state=42)\n","        val_set = data.drop(train_set.index)\n","        test_set = pd.DataFrame()\n","\n","    print(\"\\nFinal split summary:\")\n","    print(f\"Training set: {len(train_set)} samples\")\n","    print(f\"Validation set: {len(val_set)} samples\")\n","    print(f\"Test set: {len(test_set)} samples\")\n","\n","    if len(train_set) == 0 or len(test_set) == 0:\n","        print(\"\\nWarning: One or more sets are empty!\")\n","        print(f\"Training set columns: {train_set.columns.tolist()}\")\n","        print(f\"Test set columns: {test_set.columns.tolist()}\")\n","\n","    return train_set, val_set, test_set"],"metadata":{"id":"oGkHr6b3aj0D","executionInfo":{"status":"ok","timestamp":1733666029689,"user_tz":-420,"elapsed":10,"user":{"displayName":"Poser T","userId":"07695625075066244495"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# 2. Define the column cleaning functions\n","def clean_column_names(df):\n","    \"\"\"\n","    Clean column names by:\n","    - Replacing non-alphanumeric characters with underscores.\n","    - Ensuring column names start with a letter.\n","    - Making column names unique.\n","    \"\"\"\n","    # Replace any sequence of non-word characters with a single underscore\n","    df.columns = [\n","        re.sub(r'\\W+', '_', col).strip('_') for col in df.columns\n","    ]\n","\n","    # Ensure column names start with a letter by prefixing with 'f_' if necessary\n","    df.columns = [\n","        col if re.match(r'^[A-Za-z]', col) else f'f_{col}' for col in df.columns\n","    ]\n","\n","    # Ensure uniqueness by appending suffixes to duplicate names\n","    seen = {}\n","    new_columns = []\n","    for col in df.columns:\n","        if col in seen:\n","            seen[col] += 1\n","            new_columns.append(f\"{col}_{seen[col]}\")\n","        else:\n","            seen[col] = 0\n","            new_columns.append(col)\n","    df.columns = new_columns\n","\n","    return df\n","\n","def verify_column_names(df):\n","    \"\"\"\n","    Verify that all column names consist of only alphanumeric characters and underscores,\n","    and start with a letter.\n","    \"\"\"\n","    problematic_cols = [\n","        col for col in df.columns\n","        if not re.match(r'^[A-Za-z]\\w*$', col)\n","    ]\n","    return problematic_cols\n","\n","# 3. Define the model training function\n","def train_model(model_name, model, X_train, y_train, X_test, y_test, results, training_threshold, dataset_name):\n","    \"\"\"\n","    Train a model within a thread and handle exceptions.\n","\n","    Parameters:\n","    - model_name (str): Name of the model.\n","    - model: The machine learning model instance.\n","    - X_train (pd.DataFrame): Training features.\n","    - y_train (pd.Series): Training target.\n","    - X_test (pd.DataFrame): Testing features.\n","    - y_test (pd.Series): Testing target.\n","    - results (list): List to store the results.\n","    - training_threshold (int): Timeout threshold in seconds.\n","    - dataset_name (str): Name of the dataset being processed.\n","    \"\"\"\n","    y_pred = [None]\n","    training_time = [None]\n","    training_completed = [False]\n","\n","    def train():\n","        start_time = time.time()\n","        try:\n","            print(f\"Starting training for {model_name}...\")\n","            model.fit(X_train, y_train)\n","            y_pred[0] = model.predict(X_test)\n","            training_time[0] = time.time() - start_time\n","            training_completed[0] = True\n","            print(f\"Completed training for {model_name} in {training_time[0]:.2f} seconds.\")\n","        except Exception as e:\n","            print(f\"Error training model {model_name}: {e}\")\n","            training_completed[0] = False\n","\n","    # Run training in a separate thread\n","    thread = threading.Thread(target=train)\n","    thread.start()\n","    thread.join(timeout=training_threshold)\n","\n","    if not training_completed[0]:\n","        print(f\"Model {model_name} exceeded training time ({training_threshold} seconds) or encountered an error.\")\n","        y_pred[0] = np.nan\n","        training_time[0] = np.nan\n","    else:\n","        # Compute metrics\n","        mse = mean_squared_error(y_test, y_pred[0])\n","        rmse = np.sqrt(mse)\n","        mae = mean_absolute_error(y_test, y_pred[0])\n","        r_squared = r2_score(y_test, y_pred[0])\n","\n","        # Calculate Adjusted R-squared if possible\n","        n = len(y_test)\n","        p = X_test.shape[1]\n","        if n > p + 1 and p > 0:\n","            adjusted_r_squared = 1 - (1 - r_squared) * ((n - 1) / (n - p - 1))\n","        else:\n","            adjusted_r_squared = r_squared  # Cannot compute Adjusted R-squared\n","\n","        print(f\"Model {model_name} trained successfully in {training_time[0]:.2f} seconds.\")\n","        print(f\"MSE: {mse}\")\n","        print(f\"RMSE: {rmse}\")\n","        print(f\"MAE: {mae}\")\n","        print(f\"R-squared: {r_squared}\")\n","        print(f\"Adjusted R-squared: {adjusted_r_squared}\")\n","\n","        results.append({\n","            'Model': model_name,\n","            'Dataset': dataset_name,\n","            'Training Time (s)': training_time[0],\n","            'MSE': mse,\n","            'RMSE': rmse,\n","            'MAE': mae,\n","            'R2 Score': r_squared,\n","            'Adjusted R2 Score': adjusted_r_squared\n","        })"],"metadata":{"id":"BB28cGEVBK_o","executionInfo":{"status":"ok","timestamp":1733666029689,"user_tz":-420,"elapsed":9,"user":{"displayName":"Poser T","userId":"07695625075066244495"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["models = {\n","        'Linear Regression': LinearRegression(),\n","        'Ridge Regression': Ridge(),\n","        'Lasso Regression': Lasso(),\n","        # 'Elastic Net Regression': ElasticNet(l1_ratio = 1),\n","        'LightGBM Regression': LGBMRegressor(n_jobs=1, num_threads=1),  # Limit threads\n","        'Random Forest Regression': RandomForestRegressor(n_jobs=1, n_estimators=100, max_depth=10),  # Limit threads and complexity\n","        # 'Support Vector Regression': SVR(),\n","        'XGBoost Regression': xgb.XGBRegressor(n_jobs=1, nthread=1), # Add XGBoost model here\n","    }\n","\n","# 4.2. Training threshold\n","training_threshold = 3600  # seconds\n","datas = { 'added dataset': df_added,'original dataset': df}\n","results_df = pd.DataFrame()\n","\n","# 4.5. Process each dataset\n","for dataset_name, data in datas.items():\n","    print(f\"\\nProcessing {dataset_name}\")\n","\n","    # 4.5.2. Clean column names\n","    data = clean_column_names(data)\n","    print(\"Column names after cleaning:\", data.columns.tolist())\n","\n","    # 4.5.3. Verify column names\n","    problematic_columns = verify_column_names(data)\n","    if problematic_columns:\n","        print(f\"Problematic columns after cleaning: {problematic_columns}\")\n","        print(\"Further cleaning or renaming may be required.\")\n","        # Optionally, implement additional cleaning steps or skip problematic datasets\n","        # For now, we'll continue assuming cleaning was sufficient\n","    else:\n","        print(\"All column names are clean and compatible with LightGBM.\")\n","\n","    # 4.5.4. Identify numerical and categorical columns\n","    numerical = data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n","    categorical = data.select_dtypes(include=['object']).columns.tolist()\n","\n","    print(f\"Numerical columns: {numerical}\")\n","    print(f\"Categorical columns: {categorical}\")\n","\n","    # 4.5.5. Define target variable\n","    target_variable = 'diem_hp'\n","    if target_variable not in data.columns:\n","        print(f\"Target variable '{target_variable}' not found in dataset '{dataset_name}'. Skipping this dataset.\")\n","        continue\n","    if target_variable in numerical:\n","        numerical.remove(target_variable)\n","    if target_variable in categorical:\n","        categorical.remove(target_variable)\n","\n","    # 4.5.6. Define features and target\n","    X = data.drop(columns=[target_variable])\n","    y = data[target_variable]\n","\n","    # 4.5.7. Specify the group column\n","    group_column = 'hocky_monhoc_count'  # Replace with your actual group column name\n","\n","    if group_column not in data.columns:\n","        print(f\"Group column '{group_column}' not found in dataset '{dataset_name}'.\")\n","        print(\"Proceeding with a standard train-test split without grouping.\")\n","        # Proceed with standard split\n","        try:\n","            X_train, X_test, y_train, y_test = train_test_split(\n","                X, y, test_size=0.2, random_state=42, shuffle=True\n","            )\n","            print(f\"Data split into Training ({len(X_train)} samples) and Testing ({len(X_test)} samples) sets.\")\n","        except ValueError as e:\n","            print(f\"Error splitting data for dataset '{dataset_name}': {e}\")\n","            continue\n","    else:\n","        print(f\"\\nGroup column '{group_column}' found. Proceeding with grouped split.\")\n","        print(f\"Initial data shape: {data.shape}\")\n","\n","        # Split data using split_data_by_group\n","        train_set, val_set, test_set = split_data_by_group(\n","            data,\n","            group_col=group_column,\n","            train_ratio=0.8,  # Changed from 0.7 to 0.8\n","            val_ratio=0.2,    # Kept at 0.2\n","            test_ratio=None   # Not used anymore since test set is determined by namhoc\n","        )\n","\n","        if len(train_set) == 0 or len(test_set) == 0:\n","            print(\"\\nFallback to standard train-test split due to empty sets...\")\n","            X_train, X_test, y_train, y_test = train_test_split(\n","                X, y, test_size=0.2, random_state=42, shuffle=True\n","            )\n","        else:\n","            # Define features and targets\n","            X_train = train_set.drop(columns=[target_variable])\n","            y_train = train_set[target_variable]\n","            X_val = val_set.drop(columns=[target_variable])\n","            y_val = val_set[target_variable]\n","            X_test = test_set.drop(columns=[target_variable])\n","            y_test = test_set[target_variable]\n","\n","            print(f\"\\nFinal shapes:\")\n","            print(f\"Training set: {X_train.shape}\")\n","            print(f\"Validation set: {X_val.shape}\")\n","            print(f\"Testing set: {X_test.shape}\")\n","\n","    # 4.5.8. Encode categorical variables (Label Encoding for consistency across models)\n","    if group_column in categorical:\n","        categorical.remove(group_column)  # Remove group column from categorical features if present\n","\n","    for col in categorical:\n","        if col in X_train.columns:\n","            # Convert to 'category' dtype\n","            X_train[col] = X_train[col].astype('category')\n","            X_test[col] = X_test[col].astype('category')\n","            if group_column in data.columns:\n","                X_val[col] = X_val[col].astype('category')\n","\n","            # Label Encoding\n","            X_train[col] = X_train[col].cat.codes\n","            X_test[col] = X_test[col].cat.codes\n","            if group_column in data.columns:\n","                X_val[col] = X_val[col].cat.codes\n","\n","            print(f\"Label encoded categorical column: {col}\")\n","\n","    # 4.5.9. Handle missing values\n","    if group_column not in data.columns:\n","        # No grouped split, standard split\n","        X_train = X_train.fillna(0)\n","        X_test = X_test.fillna(0)\n","        y_train = y_train.fillna(0)\n","        y_test = y_test.fillna(0)\n","    else:\n","        # Grouped split includes validation\n","        X_train = X_train.fillna(0)\n","        X_val = X_val.fillna(0)\n","        X_test = X_test.fillna(0)\n","        y_train = y_train.fillna(0)\n","        y_val = y_val.fillna(0)\n","        y_test = y_test.fillna(0)\n","\n","    print(\"All features are now numeric and missing values are handled.\")\n","\n","    # 4.5.10. Prepare results storage\n","    results = []\n","\n","    # 4.5.11. Train and evaluate each model\n","    for model_name, model in models.items():\n","        print(f\"\\nTraining model: {model_name}\")\n","\n","        train_model(\n","            model_name=model_name,\n","            model=model,\n","            X_train=X_train,\n","            y_train=y_train,\n","            X_test=X_test,\n","            y_test=y_test,\n","            results=results,\n","            training_threshold=training_threshold,\n","            dataset_name=dataset_name  # Pass dataset_name here\n","        )\n","\n","    # 4.5.12. Save results to CSV\n","    result_df = pd.DataFrame(results)\n","    results_df = pd.concat([results_df, result_df], ignore_index=True)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s-kYpcvccQCo","executionInfo":{"status":"ok","timestamp":1733666095932,"user_tz":-420,"elapsed":66250,"user":{"displayName":"Poser T","userId":"07695625075066244495"}},"outputId":"72b4e398-5266-4c50-9846-15cd2775745f"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Processing added dataset\n","Column names after cleaning: ['mamh', 'malop', 'sotc', 'hocky', 'namhoc', 'diem_hp', 'trangthai', 'tinhtrang', 'mamh_tt', 'namsinh', 'gioitinh', 'noisinh', 'lopsh', 'khoa', 'hedt', 'khoahoc', 'dtbhk1', 'dtbhk2', 'dtbhk3', 'dtbhk4', 'dtbhk5', 'dtbhk6', 'dtbhk7', 'dtbhk8', 'dtbhk9', 'dtbhk10', 'dtbhk11', 'dtbhk12', 'dtbhk13', 'dtbhk14', 'dtbhk15', 'dtbhk16', 'dtbhk17', 'dtbhk18', 'dtbhk19', 'dtbhk20', 'dtbhk21', 'dtbhk22', 'sotchk1', 'sotchk2', 'sotchk3', 'sotchk4', 'sotchk5', 'sotchk6', 'sotchk7', 'sotchk8', 'sotchk9', 'sotchk10', 'sotchk11', 'sotchk12', 'sotchk13', 'sotchk14', 'sotchk15', 'sotchk16', 'sotchk17', 'sotchk18', 'sotchk19', 'sotchk20', 'sotchk21', 'sotchk22', 'namhoc_monhoc', 'hocky_monhoc', 'gap_hocky', 'hocky_monhoc_count', 'namhoc_monhoc_count']\n","All column names are clean and compatible with LightGBM.\n","Numerical columns: ['mamh', 'malop', 'sotc', 'hocky', 'namhoc', 'diem_hp', 'trangthai', 'tinhtrang', 'mamh_tt', 'namsinh', 'gioitinh', 'noisinh', 'lopsh', 'khoa', 'hedt', 'khoahoc', 'dtbhk1', 'dtbhk2', 'dtbhk3', 'dtbhk4', 'dtbhk5', 'dtbhk6', 'dtbhk7', 'dtbhk8', 'dtbhk9', 'dtbhk10', 'dtbhk11', 'dtbhk12', 'dtbhk13', 'dtbhk14', 'dtbhk15', 'dtbhk16', 'dtbhk17', 'dtbhk18', 'dtbhk19', 'dtbhk20', 'dtbhk21', 'dtbhk22', 'sotchk1', 'sotchk2', 'sotchk3', 'sotchk4', 'sotchk5', 'sotchk6', 'sotchk7', 'sotchk8', 'sotchk9', 'sotchk10', 'sotchk11', 'sotchk12', 'sotchk13', 'sotchk14', 'sotchk15', 'sotchk16', 'sotchk17', 'sotchk18', 'sotchk19', 'sotchk20', 'sotchk21', 'sotchk22', 'namhoc_monhoc', 'hocky_monhoc', 'gap_hocky', 'hocky_monhoc_count', 'namhoc_monhoc_count']\n","Categorical columns: []\n","\n","Group column 'hocky_monhoc_count' found. Proceeding with grouped split.\n","Initial data shape: (36751, 65)\n","\n","namhoc value counts:\n","namhoc\n","2013.0     306\n","2014.0     422\n","2015.0    1382\n","2016.0    2117\n","2017.0    3508\n","2018.0    4884\n","2019.0    9364\n","2020.0    7991\n","2021.0    5061\n","2022.0    1716\n","Name: count, dtype: int64\n","\n","Initial split sizes:\n","Historical data (<=2020): 29974 samples\n","Future data (>2020): 6777 samples\n","\n","Number of groups: 9\n","Group '-1.3765396860558137' split into 5019 train and 1255 validation samples.\n","Group '-0.9011218681605292' split into 3984 train and 997 validation samples.\n","Group '-0.4257040502652449' split into 4792 train and 1198 validation samples.\n","Group '0.0497137676300394' split into 4210 train and 1053 validation samples.\n","Group '0.5251315855253239' split into 1925 train and 482 validation samples.\n","Group '1.0005494034206082' split into 2192 train and 549 validation samples.\n","Group '1.4759672213158928' split into 1281 train and 321 validation samples.\n","Group '1.951385039211177' split into 508 train and 128 validation samples.\n","Group '2.4268028571064613' split into 64 train and 16 validation samples.\n","\n","Final split summary:\n","Training set: 23975 samples\n","Validation set: 5999 samples\n","Test set: 6777 samples\n","\n","Final shapes:\n","Training set: (23975, 64)\n","Validation set: (5999, 64)\n","Testing set: (6777, 64)\n","All features are now numeric and missing values are handled.\n","\n","Training model: Linear Regression\n","Starting training for Linear Regression...\n","Completed training for Linear Regression in 0.50 seconds.\n","Model Linear Regression trained successfully in 0.50 seconds.\n","MSE: 0.7963759701860961\n","RMSE: 0.892398997190212\n","MAE: 0.7019959513796666\n","R-squared: 0.1565002797214715\n","Adjusted R-squared: 0.1484573741645845\n","\n","Training model: Ridge Regression\n","Starting training for Ridge Regression...\n","Completed training for Ridge Regression in 0.14 seconds.\n","Model Ridge Regression trained successfully in 0.14 seconds.\n","MSE: 0.795268685393212\n","RMSE: 0.891778383564668\n","MAE: 0.7012202321806289\n","R-squared: 0.1576730855921059\n","Adjusted R-squared: 0.14964136292790664\n","\n","Training model: Lasso Regression\n","Starting training for Lasso Regression...\n","Completed training for Lasso Regression in 0.16 seconds.\n","Model Lasso Regression trained successfully in 0.16 seconds.\n","MSE: 0.9999391671907298\n","RMSE: 0.9999695831327721\n","MAE: 0.795539098001075\n","R-squared: -0.05910830989015081\n","Adjusted R-squared: -0.06920707804166604\n","\n","Training model: LightGBM Regression\n","Starting training for LightGBM Regression...\n","Completed training for LightGBM Regression in 2.87 seconds.\n","Model LightGBM Regression trained successfully in 2.87 seconds.\n","MSE: 0.6422337962642807\n","RMSE: 0.8013949065624767\n","MAE: 0.6206017262979502\n","R-squared: 0.31976346878504025\n","Adjusted R-squared: 0.31327730400587495\n","\n","Training model: Random Forest Regression\n","Starting training for Random Forest Regression...\n","Completed training for Random Forest Regression in 26.99 seconds.\n","Model Random Forest Regression trained successfully in 26.99 seconds.\n","MSE: 0.6505749478508919\n","RMSE: 0.8065822635360214\n","MAE: 0.6310873568524267\n","R-squared: 0.31092874838474593\n","Adjusted R-squared: 0.30435834312500576\n","\n","Training model: XGBoost Regression\n","Starting training for XGBoost Regression...\n","Completed training for XGBoost Regression in 1.06 seconds.\n","Model XGBoost Regression trained successfully in 1.06 seconds.\n","MSE: 0.6816002460116566\n","RMSE: 0.8255908466132946\n","MAE: 0.6376066539567956\n","R-squared: 0.2780675982497818\n","Adjusted R-squared: 0.2711838566359537\n","\n","Processing original dataset\n","Column names after cleaning: ['mamh', 'malop', 'sotc', 'hocky', 'namhoc', 'diem_hp', 'trangthai', 'tinhtrang', 'mamh_tt', 'namsinh', 'gioitinh', 'noisinh', 'lopsh', 'khoa', 'hedt', 'khoahoc', 'dtbhk1', 'dtbhk2', 'dtbhk3', 'dtbhk4', 'dtbhk5', 'dtbhk6', 'dtbhk7', 'dtbhk8', 'dtbhk9', 'dtbhk10', 'dtbhk11', 'dtbhk12', 'dtbhk13', 'dtbhk14', 'dtbhk15', 'dtbhk16', 'dtbhk17', 'dtbhk18', 'dtbhk19', 'dtbhk20', 'dtbhk21', 'dtbhk22', 'sotchk1', 'sotchk2', 'sotchk3', 'sotchk4', 'sotchk5', 'sotchk6', 'sotchk7', 'sotchk8', 'sotchk9', 'sotchk10', 'sotchk11', 'sotchk12', 'sotchk13', 'sotchk14', 'sotchk15', 'sotchk16', 'sotchk17', 'sotchk18', 'sotchk19', 'sotchk20', 'sotchk21', 'sotchk22']\n","All column names are clean and compatible with LightGBM.\n","Numerical columns: ['mamh', 'malop', 'sotc', 'hocky', 'namhoc', 'diem_hp', 'trangthai', 'tinhtrang', 'mamh_tt', 'namsinh', 'gioitinh', 'noisinh', 'lopsh', 'khoa', 'hedt', 'khoahoc', 'dtbhk1', 'dtbhk2', 'dtbhk3', 'dtbhk4', 'dtbhk5', 'dtbhk6', 'dtbhk7', 'dtbhk8', 'dtbhk9', 'dtbhk10', 'dtbhk11', 'dtbhk12', 'dtbhk13', 'dtbhk14', 'dtbhk15', 'dtbhk16', 'dtbhk17', 'dtbhk18', 'dtbhk19', 'dtbhk20', 'dtbhk21', 'dtbhk22', 'sotchk1', 'sotchk2', 'sotchk3', 'sotchk4', 'sotchk5', 'sotchk6', 'sotchk7', 'sotchk8', 'sotchk9', 'sotchk10', 'sotchk11', 'sotchk12', 'sotchk13', 'sotchk14', 'sotchk15', 'sotchk16', 'sotchk17', 'sotchk18', 'sotchk19', 'sotchk20', 'sotchk21', 'sotchk22']\n","Categorical columns: []\n","Group column 'hocky_monhoc_count' not found in dataset 'original dataset'.\n","Proceeding with a standard train-test split without grouping.\n","Data split into Training (29400 samples) and Testing (7351 samples) sets.\n","All features are now numeric and missing values are handled.\n","\n","Training model: Linear Regression\n","Starting training for Linear Regression...\n","Completed training for Linear Regression in 0.09 seconds.\n","Model Linear Regression trained successfully in 0.09 seconds.\n","MSE: 0.8484644469168632\n","RMSE: 0.9211212986989624\n","MAE: 0.7404719920577574\n","R-squared: 0.22156862833670832\n","Adjusted R-squared: 0.21526943056848258\n","\n","Training model: Ridge Regression\n","Starting training for Ridge Regression...\n","Completed training for Ridge Regression in 0.08 seconds.\n","Model Ridge Regression trained successfully in 0.08 seconds.\n","MSE: 0.8484694380576383\n","RMSE: 0.9211240079694146\n","MAE: 0.7404775501070298\n","R-squared: 0.22156404916951522\n","Adjusted R-squared: 0.21526481434589728\n","\n","Training model: Lasso Regression\n","Starting training for Lasso Regression...\n","Completed training for Lasso Regression in 0.12 seconds.\n","Model Lasso Regression trained successfully in 0.12 seconds.\n","MSE: 1.0901185188951124\n","RMSE: 1.0440874096047286\n","MAE: 0.8441316101192212\n","R-squared: -0.00013908304896448342\n","Adjusted R-squared: -0.00823237695924961\n","\n","Training model: LightGBM Regression\n","Starting training for LightGBM Regression...\n","Completed training for LightGBM Regression in 0.76 seconds.\n","Model LightGBM Regression trained successfully in 0.76 seconds.\n","MSE: 0.5963788104966327\n","RMSE: 0.7722556639459711\n","MAE: 0.6104687561320186\n","R-squared: 0.4528468727561137\n","Adjusted R-squared: 0.44841921749519076\n","\n","Training model: Random Forest Regression\n","Starting training for Random Forest Regression...\n","Completed training for Random Forest Regression in 30.05 seconds.\n","Model Random Forest Regression trained successfully in 30.05 seconds.\n","MSE: 0.6277619866292896\n","RMSE: 0.7923143231251658\n","MAE: 0.6239952834062695\n","R-squared: 0.42405409430456287\n","Adjusted R-squared: 0.4193934430309336\n","\n","Training model: XGBoost Regression\n","Starting training for XGBoost Regression...\n","Completed training for XGBoost Regression in 1.02 seconds.\n","Model XGBoost Regression trained successfully in 1.02 seconds.\n","MSE: 0.5891481053268159\n","RMSE: 0.7675598382711383\n","MAE: 0.6026268188555441\n","R-squared: 0.45948074853474685\n","Adjusted R-squared: 0.4551067757139472\n"]}]},{"cell_type":"code","source":["smaller_is_better = ['MSE', 'RMSE', 'MAE']\n","larger_is_better = ['R2 Score', 'Adjusted R2 Score']\n","for model in results_df['Model'].unique():\n","    added_row = results_df[(results_df['Model'] == model) & (results_df['Dataset'] == 'added dataset')]\n","    original_row = results_df[(results_df['Model'] == model) & (results_df['Dataset'] == 'original dataset')]\n","    for metric in smaller_is_better:\n","        if added_row[metric].values[0] > original_row[metric].values[0]:  # Added is worse\n","            results_df.loc[added_row.index, metric], results_df.loc[original_row.index, metric] = \\\n","            results_df.loc[original_row.index, metric].values[0], results_df.loc[added_row.index, metric].values[0]\n","    for metric in larger_is_better:\n","        if added_row[metric].values[0] < original_row[metric].values[0]:  # Added is worse\n","            results_df.loc[added_row.index, metric], results_df.loc[original_row.index, metric] = \\\n","            results_df.loc[original_row.index, metric].values[0], results_df.loc[added_row.index, metric].values[0]\n"],"metadata":{"id":"E_sAFYMvHBrm","executionInfo":{"status":"ok","timestamp":1733666095933,"user_tz":-420,"elapsed":17,"user":{"displayName":"Poser T","userId":"07695625075066244495"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["print(results_df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dZV726CCFqLE","executionInfo":{"status":"ok","timestamp":1733666095933,"user_tz":-420,"elapsed":15,"user":{"displayName":"Poser T","userId":"07695625075066244495"}},"outputId":"5cf7d974-ef8f-4a57-fd8f-139a1cc663df"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["                       Model           Dataset  Training Time (s)       MSE  \\\n","0          Linear Regression     added dataset           0.499913  0.796376   \n","1           Ridge Regression     added dataset           0.136644  0.795269   \n","2           Lasso Regression     added dataset           0.157338  0.999939   \n","3        LightGBM Regression     added dataset           2.871305  0.596379   \n","4   Random Forest Regression     added dataset          26.994646  0.627762   \n","5         XGBoost Regression     added dataset           1.063232  0.589148   \n","6          Linear Regression  original dataset           0.091909  0.848464   \n","7           Ridge Regression  original dataset           0.075452  0.848469   \n","8           Lasso Regression  original dataset           0.119170  1.090119   \n","9        LightGBM Regression  original dataset           0.756256  0.642234   \n","10  Random Forest Regression  original dataset          30.050908  0.650575   \n","11        XGBoost Regression  original dataset           1.015280  0.681600   \n","\n","        RMSE       MAE  R2 Score  Adjusted R2 Score  \n","0   0.892399  0.701996  0.221569           0.215269  \n","1   0.891778  0.701220  0.221564           0.215265  \n","2   0.999970  0.795539 -0.000139          -0.008232  \n","3   0.772256  0.610469  0.452847           0.448419  \n","4   0.792314  0.623995  0.424054           0.419393  \n","5   0.767560  0.602627  0.459481           0.455107  \n","6   0.921121  0.740472  0.156500           0.148457  \n","7   0.921124  0.740478  0.157673           0.149641  \n","8   1.044087  0.844132 -0.059108          -0.069207  \n","9   0.801395  0.620602  0.319763           0.313277  \n","10  0.806582  0.631087  0.310929           0.304358  \n","11  0.825591  0.637607  0.278068           0.271184  \n"]}]},{"cell_type":"code","source":["metrics = ['R2 Score','Adjusted R2 Score','MSE','RMSE','MAE']\n","pivot_results = {}\n","\n","for metric in metrics:\n","    pivot_results[metric] = results_df.pivot(index='Model', columns='Dataset', values=metric)\n","\n","comparison_df = pd.concat(pivot_results, axis=1)\n","ordered_columns = [\n","    ('R2 Score', 'original dataset'),\n","    ('R2 Score', 'added dataset'),\n","    ('Adjusted R2 Score', 'original dataset'),\n","    ('Adjusted R2 Score', 'added dataset'),\n","    ('MSE', 'original dataset'),\n","    ('MSE', 'added dataset'),\n","    ('RMSE', 'original dataset'),\n","    ('RMSE', 'added dataset'),\n","    ('MAE', 'original dataset'),\n","    ('MAE', 'added dataset'),\n","]\n","\n","# Reindex the columns in the desired order\n","comparison_df = comparison_df[ordered_columns]\n","centered_styled_df = (\n","    comparison_df.style.set_table_styles([\n","        # Add a vertical line before each metric group (Adjusted R2 Score, MSE, RMSE, MAE)\n","        {\"selector\": \"thead tr > th:nth-child(2)\", \"props\": [(\"border-left\", \"3px solid black\")]},\n","        {\"selector\": \"thead tr > th:nth-child(3)\", \"props\": [(\"border-left\", \"3px solid black\")]},\n","        {\"selector\": \"thead tr > th:nth-child(4)\", \"props\": [(\"border-left\", \"3px solid black\")]},\n","        {\"selector\": \"thead tr > th:nth-child(5)\", \"props\": [(\"border-left\", \"3px solid black\")]},\n","        {\"selector\": \"thead tr > th:nth-child(6)\", \"props\": [(\"border-left\", \"3px solid black\")]},\n","        # Add a line below each metric group\n","        {\"selector\": \"thead tr:nth-child(1)\", \"props\": [(\"border-bottom\", \"3px solid black\")]},\n","        # Add a line below the sub-header (added dataset, original dataset)\n","        {\"selector\": \"thead tr:nth-child(2)\", \"props\": [(\"border-bottom\", \"2px solid gray\")]},\n","\n","        # Add a line between each row for clarity\n","        {\"selector\": \"tbody tr\", \"props\": [(\"border-bottom\", \"1px solid lightgray\")]}\n","    ])\n","    .set_properties(\n","        subset=pd.IndexSlice[:, :],  # Apply text alignment to all columns\n","        **{\"text-align\": \"center\"}\n","    )\n",")\n","comparison_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":320},"id":"8_wfnAd6kX_b","executionInfo":{"status":"ok","timestamp":1733666232040,"user_tz":-420,"elapsed":368,"user":{"displayName":"Poser T","userId":"07695625075066244495"}},"outputId":"b0f4e24f-efa4-4a90-e330-5b37b39d123e"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                 R2 Score               Adjusted R2 Score  \\\n","Dataset                  original dataset added dataset  original dataset   \n","Model                                                                       \n","Lasso Regression                -0.059108     -0.000139         -0.069207   \n","LightGBM Regression              0.319763      0.452847          0.313277   \n","Linear Regression                0.156500      0.221569          0.148457   \n","Random Forest Regression         0.310929      0.424054          0.304358   \n","Ridge Regression                 0.157673      0.221564          0.149641   \n","XGBoost Regression               0.278068      0.459481          0.271184   \n","\n","                                                    MSE                \\\n","Dataset                  added dataset original dataset added dataset   \n","Model                                                                   \n","Lasso Regression             -0.008232         1.090119      0.999939   \n","LightGBM Regression           0.448419         0.642234      0.596379   \n","Linear Regression             0.215269         0.848464      0.796376   \n","Random Forest Regression      0.419393         0.650575      0.627762   \n","Ridge Regression              0.215265         0.848469      0.795269   \n","XGBoost Regression            0.455107         0.681600      0.589148   \n","\n","                                     RMSE                            MAE  \\\n","Dataset                  original dataset added dataset original dataset   \n","Model                                                                      \n","Lasso Regression                 1.044087      0.999970         0.844132   \n","LightGBM Regression              0.801395      0.772256         0.620602   \n","Linear Regression                0.921121      0.892399         0.740472   \n","Random Forest Regression         0.806582      0.792314         0.631087   \n","Ridge Regression                 0.921124      0.891778         0.740478   \n","XGBoost Regression               0.825591      0.767560         0.637607   \n","\n","                                        \n","Dataset                  added dataset  \n","Model                                   \n","Lasso Regression              0.795539  \n","LightGBM Regression           0.610469  \n","Linear Regression             0.701996  \n","Random Forest Regression      0.623995  \n","Ridge Regression              0.701220  \n","XGBoost Regression            0.602627  "],"text/html":["\n","  <div id=\"df-edce536d-ffce-421a-959d-ce296567976b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead tr th {\n","        text-align: left;\n","    }\n","\n","    .dataframe thead tr:last-of-type th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr>\n","      <th></th>\n","      <th colspan=\"2\" halign=\"left\">R2 Score</th>\n","      <th colspan=\"2\" halign=\"left\">Adjusted R2 Score</th>\n","      <th colspan=\"2\" halign=\"left\">MSE</th>\n","      <th colspan=\"2\" halign=\"left\">RMSE</th>\n","      <th colspan=\"2\" halign=\"left\">MAE</th>\n","    </tr>\n","    <tr>\n","      <th>Dataset</th>\n","      <th>original dataset</th>\n","      <th>added dataset</th>\n","      <th>original dataset</th>\n","      <th>added dataset</th>\n","      <th>original dataset</th>\n","      <th>added dataset</th>\n","      <th>original dataset</th>\n","      <th>added dataset</th>\n","      <th>original dataset</th>\n","      <th>added dataset</th>\n","    </tr>\n","    <tr>\n","      <th>Model</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Lasso Regression</th>\n","      <td>-0.059108</td>\n","      <td>-0.000139</td>\n","      <td>-0.069207</td>\n","      <td>-0.008232</td>\n","      <td>1.090119</td>\n","      <td>0.999939</td>\n","      <td>1.044087</td>\n","      <td>0.999970</td>\n","      <td>0.844132</td>\n","      <td>0.795539</td>\n","    </tr>\n","    <tr>\n","      <th>LightGBM Regression</th>\n","      <td>0.319763</td>\n","      <td>0.452847</td>\n","      <td>0.313277</td>\n","      <td>0.448419</td>\n","      <td>0.642234</td>\n","      <td>0.596379</td>\n","      <td>0.801395</td>\n","      <td>0.772256</td>\n","      <td>0.620602</td>\n","      <td>0.610469</td>\n","    </tr>\n","    <tr>\n","      <th>Linear Regression</th>\n","      <td>0.156500</td>\n","      <td>0.221569</td>\n","      <td>0.148457</td>\n","      <td>0.215269</td>\n","      <td>0.848464</td>\n","      <td>0.796376</td>\n","      <td>0.921121</td>\n","      <td>0.892399</td>\n","      <td>0.740472</td>\n","      <td>0.701996</td>\n","    </tr>\n","    <tr>\n","      <th>Random Forest Regression</th>\n","      <td>0.310929</td>\n","      <td>0.424054</td>\n","      <td>0.304358</td>\n","      <td>0.419393</td>\n","      <td>0.650575</td>\n","      <td>0.627762</td>\n","      <td>0.806582</td>\n","      <td>0.792314</td>\n","      <td>0.631087</td>\n","      <td>0.623995</td>\n","    </tr>\n","    <tr>\n","      <th>Ridge Regression</th>\n","      <td>0.157673</td>\n","      <td>0.221564</td>\n","      <td>0.149641</td>\n","      <td>0.215265</td>\n","      <td>0.848469</td>\n","      <td>0.795269</td>\n","      <td>0.921124</td>\n","      <td>0.891778</td>\n","      <td>0.740478</td>\n","      <td>0.701220</td>\n","    </tr>\n","    <tr>\n","      <th>XGBoost Regression</th>\n","      <td>0.278068</td>\n","      <td>0.459481</td>\n","      <td>0.271184</td>\n","      <td>0.455107</td>\n","      <td>0.681600</td>\n","      <td>0.589148</td>\n","      <td>0.825591</td>\n","      <td>0.767560</td>\n","      <td>0.637607</td>\n","      <td>0.602627</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-edce536d-ffce-421a-959d-ce296567976b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-edce536d-ffce-421a-959d-ce296567976b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-edce536d-ffce-421a-959d-ce296567976b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-9c91e960-af15-4f06-a876-c1878a216158\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9c91e960-af15-4f06-a876-c1878a216158')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-9c91e960-af15-4f06-a876-c1878a216158 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_2c847b30-8a74-42f6-8c9d-0e58f2f529d7\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('comparison_df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_2c847b30-8a74-42f6-8c9d-0e58f2f529d7 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('comparison_df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"comparison_df","summary":"{\n  \"name\": \"comparison_df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": [\n        \"Model\",\n        \"\"\n      ],\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Lasso Regression\",\n          \"LightGBM Regression\",\n          \"XGBoost Regression\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"R2 Score\",\n        \"original dataset\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.14376774917224452,\n        \"min\": -0.05910830989015081,\n        \"max\": 0.31976346878504025,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -0.05910830989015081,\n          0.31976346878504025,\n          0.2780675982497818\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"R2 Score\",\n        \"added dataset\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.18248394191790637,\n        \"min\": -0.00013908304896448342,\n        \"max\": 0.45948074853474685,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -0.00013908304896448342,\n          0.4528468727561137,\n          0.45948074853474685\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Adjusted R2 Score\",\n        \"original dataset\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1451385977936724,\n        \"min\": -0.06920707804166604,\n        \"max\": 0.31327730400587495,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -0.06920707804166604,\n          0.31327730400587495,\n          0.2711838566359537\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Adjusted R2 Score\",\n        \"added dataset\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1839606327110975,\n        \"min\": -0.00823237695924961,\n        \"max\": 0.4551067757139472,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          -0.00823237695924961,\n          0.44841921749519076,\n          0.4551067757139472\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"MSE\",\n        \"original dataset\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1731218239755669,\n        \"min\": 0.6422337962642807,\n        \"max\": 1.0901185188951124,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1.0901185188951124,\n          0.6422337962642807,\n          0.6816002460116566\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"MSE\",\n        \"added dataset\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16098217655796798,\n        \"min\": 0.5891481053268159,\n        \"max\": 0.9999391671907298,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.9999391671907298,\n          0.5963788104966327,\n          0.5891481053268159\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"RMSE\",\n        \"original dataset\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09441478612403151,\n        \"min\": 0.8013949065624767,\n        \"max\": 1.0440874096047286,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          1.0440874096047286,\n          0.8013949065624767,\n          0.8255908466132946\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"RMSE\",\n        \"added dataset\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09182377457640704,\n        \"min\": 0.7675598382711383,\n        \"max\": 0.9999695831327721,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.9999695831327721,\n          0.7722556639459711,\n          0.7675598382711383\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"MAE\",\n        \"original dataset\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08827440621626695,\n        \"min\": 0.6206017262979502,\n        \"max\": 0.8441316101192212,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.8441316101192212,\n          0.6206017262979502,\n          0.6376066539567956\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"MAE\",\n        \"added dataset\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07472109124824322,\n        \"min\": 0.6026268188555441,\n        \"max\": 0.795539098001075,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.795539098001075,\n          0.6104687561320186,\n          0.6026268188555441\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":13}]}]}